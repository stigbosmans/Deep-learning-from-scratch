{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.49139969, 0.48215842, 0.44653093], [0.20220212, 0.19931542, 0.20086347])\n",
    "])\n",
    "training_data = CIFAR10('cifar/train', train=True, download=True, transform=transform)\n",
    "test_data = CIFAR10('cifar/test', train=False, download=True, transform=transform)\n",
    "loader = DataLoader(training_data, 32, sampler=sampler.SubsetRandomSampler(range(49000)))\n",
    "loader_val = DataLoader(training_data, 32, sampler=sampler.SubsetRandomSampler(range(49000,50000)))\n",
    "loader_test = DataLoader(test_data, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-09c843c47ac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mstds\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mcalc_normalize_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-09c843c47ac0>\u001b[0m in \u001b[0;36mcalc_normalize_values\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mmeans\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mstds\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\stig\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\stig\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\stig\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\stig\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#calculate dataset mean and std per channel to feed to transform normalization params\n",
    "def calc_normalize_values():\n",
    "    means = np.zeros(3)\n",
    "    stds = np.zeros(3)\n",
    "    N = len(training_data)\n",
    "    for i, (data, label) in enumerate(training_data):\n",
    "        means += data.numpy().mean(axis=(1,2))\n",
    "        stds += data.numpy().std(axis=(1,2))\n",
    "    means /= N\n",
    "    stds /= N\n",
    "    print(means, stds)\n",
    "calc_normalize_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "(data, labels) = next(iter(loader))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cc848daa90>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = data[5].numpy()\n",
    "plt.imshow(im.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using ' + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5045,  0.6658,  0.0638,  ..., -0.4751,  0.0172, -0.6940],\n",
      "        [-0.6513,  0.4712,  1.8089,  ...,  1.0736,  1.7470, -0.5053],\n",
      "        [ 0.4007, -0.8646, -0.3317,  ..., -0.8382,  0.8380, -0.2044],\n",
      "        ...,\n",
      "        [-0.4110, -0.2545, -0.6829,  ...,  1.2339,  0.4452, -1.0692],\n",
      "        [-0.2678, -0.0914, -0.5150,  ...,  0.6717, -0.5911,  0.0696],\n",
      "        [ 0.4564,  1.2580, -0.3034,  ..., -0.1088, -1.0548, -0.8330]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "p={}\n",
    "p['W1'] = torch.randn((32, 3, 5, 5), dtype=torch.float32, device=device)\n",
    "p['W1'].requires_grad = True\n",
    "p['b1'] = torch.zeros((32,), dtype=torch.float32, requires_grad=True, device=device)\n",
    "p['W2'] = torch.randn((16, 32, 3, 3), dtype=torch.float32, device=device)\n",
    "p['W2'].requires_grad = True\n",
    "p['b2'] = torch.zeros((16,), dtype=torch.float32, requires_grad=True, device=device)\n",
    "p['W3'] = torch.randn((16*32*32, 10), dtype=torch.float32, device=device)\n",
    "p['W3'].requires_grad = True\n",
    "p['b3'] = torch.zeros((10,), dtype=torch.float32, requires_grad=True, device=device)\n",
    "print(p['W3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet(x, params):\n",
    "    a1 = F.conv2d(x, weight=params['W1'], bias=params['b1'], padding=2)\n",
    "    z1 = F.relu(a1)\n",
    "    a2 = F.conv2d(z1, weight=params['W2'], bias=params['b2'], padding=1)\n",
    "    z2 = F.relu(a2)\n",
    "    z2 = z2.view(z2.shape[0], -1)\n",
    "    a3 = z2.mm(params['W3']) + params['b3']\n",
    "    return a3\n",
    "\n",
    "#scores = convnet(data, p)\n",
    "#loss = torch.nn.CrossEntropyLoss()\n",
    "#cost = loss(scores, labels)\n",
    "#cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader_test.dataset)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy():\n",
    "    acc = 0\n",
    "    num_samples = 0\n",
    "    for i, (data, labels) in enumerate(loader_val):\n",
    "        scores = convnet(data, p)\n",
    "        res = scores.argmax(dim=1)\n",
    "        correct = res == labels\n",
    "        acc += correct.sum().float()/labels.shape[0]\n",
    "        num_samples += 1\n",
    "    acc /= num_samples\n",
    "    return float(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, cost is 10683.874023, test accuracy is\n",
      "iteration 100, cost is 4.138242, test accuracy is\n",
      "iteration 200, cost is 4.231732, test accuracy is\n",
      "iteration 300, cost is 2.302662, test accuracy is\n",
      "iteration 400, cost is 2.997514, test accuracy is\n",
      "iteration 500, cost is 3.724355, test accuracy is\n",
      "iteration 600, cost is 2.626307, test accuracy is\n",
      "iteration 700, cost is 2.301603, test accuracy is\n",
      "iteration 800, cost is 2.230615, test accuracy is\n",
      "iteration 900, cost is 2.348959, test accuracy is\n",
      "iteration 1000, cost is 5.253799, test accuracy is\n",
      "iteration 1100, cost is 2.361798, test accuracy is\n",
      "iteration 1200, cost is 2.327778, test accuracy is\n",
      "iteration 1300, cost is 2.302998, test accuracy is\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-870941ff573a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-fedbe816b652>\u001b[0m in \u001b[0;36mconvnet\u001b[1;34m(x, params)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mz2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mz2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, (data, labels) in enumerate(loader):\n",
    "    data = data.to(device=device, dtype=torch.float32)\n",
    "    labels = labels.to(device=device, dtype=torch.long)\n",
    "    scores = convnet(data, p)\n",
    "    cost = F.cross_entropy(scores, labels)\n",
    "    cost.backward()\n",
    "    with torch.no_grad():\n",
    "        for k,w in p.items():\n",
    "            w -= 3e-3 * w.grad\n",
    "            w.grad.zero_()\n",
    "    if idx % 100 == 0:\n",
    "        print('iteration %d, cost is %f, test accuracy is' % (idx, float(cost)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-784c2c7c4168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;36m2.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'tuple'"
     ]
    }
   ],
   "source": [
    "a=(2,3,4)\n",
    "2./a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
